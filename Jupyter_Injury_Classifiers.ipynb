{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best Margin (C) for Support Vector Machine Classification\n",
      "Testing Margin Value: 0.1 / 4 \tFound score: 0.8450363196125908\n",
      "Testing Margin Value: 0.6 / 4 \tFound score: 0.8450363196125908\n",
      "Testing Margin Value: 1.1 / 4 \tFound score: 0.8490718321226796\n",
      "Testing Margin Value: 1.6 / 4 \tFound score: 0.8595641646489104\n",
      "Testing Margin Value: 2.1 / 4 \tFound score: 0.8958837772397095\n",
      "Testing Margin Value: 2.6 / 4 \tFound score: 0.9426957223567393\n",
      "Testing Margin Value: 3.1 / 4 \tFound score: 0.9620661824051655\n",
      "Testing Margin Value: 3.6 / 4 \tFound score: 0.9733656174334141\n",
      "best c: 3.6\n",
      "Finding the best layer size for the MLP Classification\n",
      "Testing Layer size: 13 / 20 \tFound score: 0.8450363196125908\n",
      "Testing Layer size: 14 / 20 \tFound score: 0.8450363196125908\n",
      "Testing Layer size: 15 / 20 \tFound score: 1.0\n",
      "Testing Layer size: 16 / 20 \tFound score: 0.8450363196125908\n",
      "Testing Layer size: 17 / 20 \tFound score: 0.8450363196125908\n",
      "Testing Layer size: 18 / 20 \tFound score: 0.8450363196125908\n",
      "Testing Layer size: 19 / 20 \tFound score: 0.8450363196125908\n",
      "Best Hidden Layer Size: 13\n",
      "Finding Best Nearest Neighbors\n",
      "Testing Neighbors: 1 / 10 \tFound score: 0.9297820823244553\n",
      "Testing Neighbors: 2 / 10 \tFound score: 0.8910411622276029\n",
      "Testing Neighbors: 3 / 10 \tFound score: 0.9007263922518159\n",
      "Testing Neighbors: 4 / 10 \tFound score: 0.8813559322033898\n",
      "Testing Neighbors: 5 / 10 \tFound score: 0.8853914447134786\n",
      "Testing Neighbors: 6 / 10 \tFound score: 0.8732849071832123\n",
      "Testing Neighbors: 7 / 10 \tFound score: 0.880548829701372\n",
      "Testing Neighbors: 8 / 10 \tFound score: 0.8692493946731235\n",
      "Testing Neighbors: 9 / 10 \tFound score: 0.8757062146892656\n",
      "Found best neighbors: 1\n",
      "\n",
      "\n",
      "===========================================================\n",
      "K-Nearest Kneighbors accuracy: 0.9297820823244553\n",
      "Support Vector Classification accuracy: 0.9733656174334141\n",
      "Multi Layer Perceptron Classification accuracy: 0.8450363196125908\n",
      "Ensemble of the three Classifiers KNN, SVM, MLP accuracy: 0.9192897497982244\n",
      "===========================================================\n",
      "\n",
      "\n",
      "\n",
      "========================================\n",
      "Matrix for model: KNN\n",
      "Injured  Uinjured\n",
      "[[1045   85]\n",
      " [   2  107]]\n",
      "========================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Matrix for model: SVM\n",
      "Injured  Uinjured\n",
      "[[1047   33]\n",
      " [   0  159]]\n",
      "========================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Matrix for model: MLP\n",
      "Injured  Uinjured\n",
      "[[1047  192]\n",
      " [   0    0]]\n",
      "========================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Matrix for model: Ensemble\n",
      "Injured  Uinjured\n",
      "[[1047  100]\n",
      " [   0   92]]\n",
      "========================================\n",
      "\n",
      "Dumped model to: model/model_nb.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Injury Prediction\n",
    "#\n",
    "\n",
    "###############################################################################\n",
    "def main():\n",
    "    data = load_data()\n",
    "    X_1, X_2, Y_1, Y_2, columns = split_data(data)\n",
    "    best_model = train_clf(X_1, X_2, Y_1, Y_2, columns)\n",
    "    dump_regs(best_model)\n",
    "    return\n",
    "\n",
    "###############################################################################\n",
    "#\n",
    "# Load the Dataset from a CSV file\n",
    "#\n",
    "def load_data():\n",
    "    import pandas as pd\n",
    "    path='injured-and-uninjured.csv'\n",
    "    df=pd.read_csv(path, sep=',', header=0)\n",
    "    data = df.drop(df.columns[0], axis=1)\n",
    "    data = data.to_dict(orient='records')\n",
    "    return data\n",
    "\n",
    "###############################################################################\n",
    "#\n",
    "# Split the imported CSV file into Training and Testing Datasets\n",
    "# \n",
    "def split_data(data):\n",
    "    from sklearn.feature_extraction import DictVectorizer\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from pandas import DataFrame\n",
    "    vec = DictVectorizer()\n",
    "\n",
    "    df_data = vec.fit_transform(data).toarray()\n",
    "    feature_names = vec.get_feature_names()\n",
    "    df_data = DataFrame(\n",
    "    df_data,\n",
    "    columns=feature_names)\n",
    "    #print(feature_names)\n",
    "    outcome_feature = df_data['Injured']\n",
    "    target_features = df_data.drop('Injured', axis=1)\n",
    "    \n",
    "    \"\"\"\n",
    "    X_1: independent variables for first data set\n",
    "    Y_1: dependent (target) variable for first data set\n",
    "    X_2: independent variables for the second data set\n",
    "    Y_2: dependent (target) variable for the second data set\n",
    "    \"\"\"\n",
    "    \n",
    "    X_1, X_2, Y_1, Y_2 = train_test_split(\n",
    "            target_features, outcome_feature, test_size=0.5, random_state=0)\n",
    "    \n",
    "    return X_1, X_2, Y_1, Y_2, feature_names\n",
    "\n",
    "###############################################################################\n",
    "#\n",
    "# Trains Each of the classifiers and finds prints their accuracy scores\n",
    "#\n",
    "def train_clf(X_1, X_2, Y_1, Y_2, columns):                       \n",
    "    #from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn import svm\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.ensemble import VotingClassifier\n",
    "    \n",
    "    # Support Vector Classifior -> find best margin\n",
    "    best_c = find_best_c(X_1, X_2, Y_1, Y_2)\n",
    "    svm_clf = svm.SVC(C=best_c, gamma=\"auto\")\n",
    "    svm_clf.fit(X_1,Y_1)\n",
    "    \n",
    "    # Find the best number of hidden layers for the MLP\n",
    "    best_hidden = find_best_layers(X_1, X_2, Y_1, Y_2)\n",
    "    mlp_clf = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(best_hidden), random_state = 1)\n",
    "    mlp_clf.fit(X_1, Y_1)\n",
    "    \n",
    "    # Find the best number of neighbors for the KNN Classifier\n",
    "    best_neighbors = find_best_number_neighbors(X_1, X_2, Y_1, Y_2)\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors = best_neighbors)\n",
    "    knn_clf.fit(X_1,Y_1)\n",
    "    \n",
    "    # Logistic Regression\n",
    "    #log_reg = LogisticRegression()\n",
    "    #log_reg.fit(X_1,Y_1)   \n",
    "    \n",
    "    \n",
    "    #ensemble of all previous\n",
    "    voting_clf = VotingClassifier(estimators=[('knn', knn_clf), ('mlp', mlp_clf), ('svr', svm_clf)])\n",
    "    voting_clf.fit(X_1, Y_1)\n",
    "    \n",
    "    #score_log = log_reg.score(X_2, Y_2)\n",
    "    score_knn = knn_clf.score(X_2, Y_2)\n",
    "    score_svr = svm_clf.score(X_2, Y_2)\n",
    "    score_mlp = mlp_clf.score(X_2, Y_2)\n",
    "    score_ensemble = voting_clf.score(X_2, Y_2)\n",
    "    \n",
    "    \n",
    "                \n",
    "    #score_ensemble =\n",
    "    print(\"\\n\\n===========================================================\")\n",
    "    #print (\"Logestic Classification accuracy: {0}\".format(score_log.mean()))\n",
    "    print (\"K-Nearest Kneighbors accuracy: {0}\".format(score_knn.mean()))\n",
    "    print (\"Support Vector Classification accuracy: {0}\".format(score_svr.mean()))\n",
    "    print (\"Multi Layer Perceptron Classification accuracy: {0}\".format(score_mlp.mean()))\n",
    "    print (\"Ensemble of the three Classifiers KNN, SVM, MLP accuracy: {0}\".format(score_ensemble.mean()))\n",
    "    print(\"===========================================================\\n\\n\")\n",
    "    \n",
    "    print_matrix(knn_clf, X_2, Y_2, 'KNN')\n",
    "    #print_matrix(log_clf, X_2, Y_2, 'Log')\n",
    "    print_matrix(svm_clf, X_2, Y_2, 'SVM')\n",
    "    print_matrix(mlp_clf, X_2, Y_2, 'MLP')\n",
    "    print_matrix(voting_clf, X_2, Y_2, 'Ensemble')\n",
    "    \n",
    "    #scores = [log_reg.score(X_2, Y_2), knn_reg.score(X_2, Y_2), svr_reg.score(X_2, Y_2), mlp_reg.score(X_2, Y_2), voting_reg.score(X_2, Y_2)]\n",
    "    #models = [log_reg, knn_reg, svr_reg, mlp_reg, voting_reg]\n",
    "    return svm_clf\n",
    "###############################################################################\n",
    "#\n",
    "# Finds the best Single Layer Size for a Multi Layer Perceptron Classifior\n",
    "#\n",
    "def find_best_layers(X_1, X_2, Y_1, Y_2):\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    print(\"Finding the best layer size for the MLP Classification\")\n",
    "    layer_size = 13\n",
    "    best_score = 0\n",
    "    best_hidden = layer_size\n",
    "    TOTAL_TEST_SIZE = 20\n",
    "    while (layer_size < TOTAL_TEST_SIZE):\n",
    "        nn_clf = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(layer_size), random_state = 1)\n",
    "        nn_clf.fit(X_1, Y_1)   \n",
    "        score = nn_clf.score(X_2, Y_2, sample_weight=None)\n",
    "        print(\"Testing Layer size: \" + str(layer_size), \"/\", str(TOTAL_TEST_SIZE), \"\\tFound score:\", str(score))\n",
    "        \n",
    "        if (score > best_score and score != 1.0):\n",
    "            best_score = score\n",
    "            best_hidden = layer_size\n",
    "            \n",
    "        layer_size += 1\n",
    "    print(\"Best Hidden Layer Size: \" + str(best_hidden))\n",
    "    return best_hidden\n",
    "\n",
    "###############################################################################\n",
    "#\n",
    "# Finds the best Margin for the Support Vector Classifior by performing grid search\n",
    "#\n",
    "def find_best_c(X_1, X_2, Y_1, Y_2):\n",
    "    from sklearn import svm\n",
    "    print(\"Finding best Margin (C) for Support Vector Machine Classification\")\n",
    "    c = 0.1\n",
    "    best_c = c\n",
    "    best_score = 0\n",
    "    TOTAL_TEST_SIZE = 4\n",
    "    while (c < TOTAL_TEST_SIZE):\n",
    "        svm_reg = svm.SVC(C=c, gamma=\"auto\")\n",
    "        svm_reg.fit(X_1,Y_1)\n",
    "        \n",
    "        score_svm = svm_reg.score(X_2, Y_2)\n",
    "        print(\"Testing Margin Value: \" + str(c), \"/\", str(TOTAL_TEST_SIZE), \"\\tFound score:\", str(score_svm))\n",
    "        if (score_svm > best_score):\n",
    "            best_score = score_svm\n",
    "            best_c = c\n",
    "        c += 0.5\n",
    "        \n",
    "    print(\"best c: \" + str(best_c))\n",
    "    return best_c\n",
    "\n",
    "###############################################################################\n",
    "#\n",
    "# Finds the best number of neighbors for a K nearest neighbors Classifior\n",
    "#\n",
    "def find_best_number_neighbors(X_1, X_2, Y_1, Y_2):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    print(\"Finding Best Nearest Neighbors\")\n",
    "    best_num_neighbors = 1\n",
    "    best_score = 0\n",
    "    i = 1\n",
    "    TOTAL_TEST_SIZE = 10\n",
    "    while (i < TOTAL_TEST_SIZE):\n",
    "        \n",
    "        knn_reg = KNeighborsClassifier(n_neighbors= i)\n",
    "        knn_reg.fit(X_1,Y_1)\n",
    "        score_knn = knn_reg.score(X_2, Y_2)\n",
    "        print(\"Testing Neighbors: \" + str(i), \"/\", str(TOTAL_TEST_SIZE), \"\\tFound score:\", str(score_knn))\n",
    "        if (score_knn > best_score):\n",
    "            best_score = score_knn\n",
    "            best_num_neighbors = i\n",
    "        i += 1\n",
    "    \n",
    "    print(\"Found best neighbors: \" + str(best_num_neighbors))\n",
    "    return best_num_neighbors\n",
    "\n",
    "###############################################################################\n",
    "#\n",
    "# Prints the confusion Matrix for a given model\n",
    "#\n",
    "def print_matrix(model, X_2, Y_2, model_name):\n",
    "    print(\"\\n========================================\")\n",
    "    print(\"Matrix for model: \" + model_name)\n",
    "    print(\"Injured  Uinjured\")\n",
    "    output = model.predict(X_2)\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    matrix = confusion_matrix(output, Y_2)\n",
    "    print (matrix)\n",
    "    print(\"========================================\\n\")\n",
    "    return\n",
    "    \n",
    "###############################################################################\n",
    "#\n",
    "# Dumps the Classifiors into a file\n",
    "#\n",
    "def dump_regs(best_model):\n",
    "    FILE_DUMP = 'model/model_nb.pkl'\n",
    "    from sklearn.externals import joblib\n",
    "    joblib.dump(best_model, FILE_DUMP)\n",
    "    print(\"Dumped model to: \" + FILE_DUMP)\n",
    "    return\n",
    "\n",
    "###############################################################################\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
